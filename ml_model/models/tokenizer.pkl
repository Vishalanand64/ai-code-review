# Save dummy tokenizer
import pickle
from tensorflow.keras.preprocessing.text import Tokenizer

tokenizer = Tokenizer(num_words=5000, oov_token="<OOV>")
tokenizer.fit_on_texts([
    "let a = 10;", 
    "const sum = (a, b) => a + b;",
    "function greet(name) { console.log(name); }"
])

with open("models/tokenizer.pkl", "wb") as f:
    pickle.dump(tokenizer, f)
